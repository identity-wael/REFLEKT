---
title: Setup Guide
description: Get REFLEKT Console running in under 5 minutes
---

import { Steps, Tabs, Callout } from 'nextra/components'

# Getting Started

Get REFLEKT Console up and running in under 5 minutes. This guide will help you set up the multi-model AI chat platform with GPT-4o as the primary model, plus support for Claude, Gemini and other leading AI providers.

<Callout type="info">
**Monorepo Structure**: The console is part of a Turborepo-powered monorepo. You can run commands either from the monorepo root using `pnpm turbo --filter=console` or directly from the `console` directory.
</Callout>

## Prerequisites

Before you begin, ensure you have:

- **Node.js 22+** and **pnpm 9.14+**
- **Git** for version control
- **Supabase Account** (free tier works)
- **AI Provider Keys** (at least one):
  - OpenAI API key (required for GPT-4o primary model)
  - Anthropic API key (optional for Claude 3 Opus)
  - Google AI API key (optional for Gemini Pro)
  - Mistral, xAI, Perplexity (optional alternatives)
- **HeyGen API Key** (optional, for interactive avatars)

<Callout type="info">
The console uses GPT-4o as the primary model with support for 8+ AI providers through Vercel AI SDK v5. OpenAI API key is required for the main functionality.
</Callout>

## Installation

<Tabs items={['pnpm', 'Full Setup', 'Docker']}>
  <Tabs.Tab>
    **Using pnpm**

    ```bash
    # Clone the repository
    git clone https://github.com/identity-wael/reflekt-ai.git
    cd reflekt-ai

    # Install dependencies for all workspaces
    pnpm install

    # Copy environment template
    cp .env.example .env.local

    # Add your Supabase and OpenAI keys to .env.local
    # NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
    # NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
    # OPENAI_API_KEY=your_openai_key

    # Start development server (from monorepo root)
    pnpm turbo dev --filter=console

    # Or from the console directory
    cd console && pnpm dev
    ```

    Access the application at `http://localhost:3000`
  </Tabs.Tab>

  <Tabs.Tab>
    **Full Setup with All Features**

    <Steps>
    ### Clone and Install

    ```bash
    git clone https://github.com/identity-wael/reflekt-ai.git
    cd reflekt-ai
    pnpm install
    ```

    ### Set Up Supabase

    1. Create a new Supabase project at [supabase.com](https://supabase.com)
    2. Get your project URL and anon key from Settings â†’ API
    3. Run the database migrations:

    ```bash
    # Copy migration files to your Supabase project
    # Go to SQL Editor in Supabase Dashboard and run:
    ```

    ```sql
    -- Create users table
    CREATE TABLE IF NOT EXISTS users (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      email TEXT UNIQUE,
      created_at TIMESTAMP DEFAULT NOW(),
      is_anonymous BOOLEAN DEFAULT false,
      daily_message_count INTEGER DEFAULT 0,
      daily_pro_message_count INTEGER DEFAULT 0,
      last_message_reset TIMESTAMP DEFAULT NOW()
    );

    -- Create chats table
    CREATE TABLE IF NOT EXISTS chats (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      user_id UUID REFERENCES users(id) ON DELETE CASCADE,
      title TEXT,
      model TEXT,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    );

    -- Create messages table
    CREATE TABLE IF NOT EXISTS messages (
      id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
      chat_id UUID REFERENCES chats(id) ON DELETE CASCADE,
      role TEXT NOT NULL,
      content TEXT NOT NULL,
      model TEXT,
      created_at TIMESTAMP DEFAULT NOW()
    );

    -- Enable Row Level Security
    ALTER TABLE users ENABLE ROW LEVEL SECURITY;
    ALTER TABLE chats ENABLE ROW LEVEL SECURITY;
    ALTER TABLE messages ENABLE ROW LEVEL SECURITY;
    ```

    ### Configure Environment Variables

    Create `.env.local` with all required keys:

    ```env
    # Supabase (Required)
    NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
    NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
    SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

    # AI Providers (OpenAI required for GPT-4o)
    OPENAI_API_KEY=sk-...  # Required for primary model
    ANTHROPIC_API_KEY=sk-ant-...  # Optional for Claude 3 Opus
    GOOGLE_AI_API_KEY=AIza...  # Optional for Gemini Pro
    MISTRAL_API_KEY=...  # Optional alternative
    XAI_API_KEY=xai-...  # Optional alternative
    PERPLEXITY_API_KEY=pplx-...  # Optional alternative
    DEEPSEEK_API_KEY=...  # Optional alternative

    # Interactive Avatars (Optional)
    NEXT_PUBLIC_HEYGEN_API_KEY=...
    HEYGEN_SECRET_KEY=...

    # Voice Mode (Optional, requires OpenAI)
    NEXT_PUBLIC_OPENAI_API_KEY=sk-...

    # Optional Services
    OPENROUTER_API_KEY=...
    OLLAMA_BASE_URL=http://localhost:11434
    ```

    ### Set Up Storage Bucket

    Run this in Supabase SQL Editor:

    ```sql
    -- Create storage bucket for file uploads
    INSERT INTO storage.buckets (id, name, public)
    VALUES ('chat-files', 'chat-files', true);

    -- Set up RLS policies for storage
    CREATE POLICY "Anyone can upload files" ON storage.objects
    FOR INSERT WITH CHECK (bucket_id = 'chat-files');

    CREATE POLICY "Anyone can view files" ON storage.objects
    FOR SELECT USING (bucket_id = 'chat-files');
    ```

    ### Start Development Server

    ```bash
    # From monorepo root
    pnpm turbo dev --filter=console

    # Or from console directory
    cd console && pnpm dev
    ```

    Visit `http://localhost:3000` and start chatting!
    </Steps>
  </Tabs.Tab>

  <Tabs.Tab>
    **Docker Setup**

    ```bash
    # Clone the repository
    git clone https://github.com/identity-wael/reflekt-ai.git
    cd reflekt-ai/console

    # Create .env.local with your keys
    cp .env.example .env.local
    # Edit .env.local with your API keys

    # Run with Docker Compose
    docker-compose up -d

    # Or with Ollama for local models
    docker-compose -f docker-compose.ollama.yml up -d
    ```

    Access at `http://localhost:3000`
  </Tabs.Tab>
</Tabs>

## First Steps

<Steps>
### Test Multi-Model Chat

Try chatting with different AI models:

```typescript
// The console uses Vercel AI SDK v5
// Models are configured in lib/models/index.ts

import { openai } from '@ai-sdk/openai';
import { anthropic } from '@ai-sdk/anthropic';
import { google } from '@ai-sdk/google';
import { mistral } from '@ai-sdk/mistral';
import { xai } from '@ai-sdk/xai';

// Example: Stream a response from GPT-4o (primary model)
const result = await streamText({
  model: openai('gpt-4o'),
  messages: [
    { role: 'user', content: 'Explain how to use this chat platform' }
  ],
});
```

### Enable Interactive Avatars

If you have a HeyGen API key, test the avatar feature:

1. Click the **Avatar** button in the chat interface
2. Select an avatar from the gallery
3. Start a session and interact with voice + video

```typescript
// Avatar session management in app/api/heygen/create-session/route.ts
const response = await fetch('/api/heygen/create-session', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    avatarId: 'josh_lite3_20230714',
    voice: { voiceId: 'en-US-BrianNeural' }
  })
});

const { sessionId, sdp } = await response.json();
// Use WebRTC to establish connection
```

### Try Voice Mode

With an OpenAI API key, enable real-time voice conversations:

1. Click the **Voice** button in chat
2. Allow microphone access
3. Speak naturally - the AI responds in real-time

```typescript
// Voice mode uses GPT-4o Realtime API
// WebSocket connection in app/components/chat/voice-mode-realtime.tsx

const ws = new WebSocket('wss://api.openai.com/v1/realtime');
ws.onopen = () => {
  ws.send(JSON.stringify({
    type: 'session.update',
    session: {
      modalities: ['text', 'audio'],
      voice: 'alloy'
    }
  }));
};
```

### Upload and Analyze Files

Test file upload capabilities:

```typescript
// File upload handling in app/components/chat-input/file-upload.tsx
const handleFileUpload = async (file: File) => {
  // Upload to Supabase Storage
  const { data, error } = await supabase.storage
    .from('chat-files')
    .upload(`${userId}/${file.name}`, file);

  // Analyze with AI
  const response = await fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({
      message: 'Analyze this file',
      fileUrl: data.publicUrl
    })
  });
};
```

### Customize Your Experience

Explore settings to personalize:

- **Model Visibility**: Show/hide specific AI models
- **Theme**: Switch between light/dark/system themes
- **System Prompt**: Set a custom personality for the AI
- **API Keys**: Add your own keys for more providers
</Steps>

## Core API Routes

The console includes these main API endpoints:

<Tabs items={['Chat', 'Avatar', 'Voice', 'Storage']}>
  <Tabs.Tab>
    **Chat API Routes**

    ```typescript
    // app/api/chat/route.ts
    // Main chat endpoint supporting all AI providers
    export async function POST(req: Request) {
      const { messages, model } = await req.json();

      // Get the AI provider and model
      const provider = getProviderFromModel(model);

      // Stream the response
      const result = await streamText({
        model: provider(model),
        messages,
        onFinish: async ({ text }) => {
          // Save to database
          await saveMessage(chatId, text);
        }
      });

      return result.toDataStreamResponse();
    }
    ```

    ```typescript
    // app/api/models/route.ts
    // Get available models based on API keys
    export async function GET() {
      const models = await getAvailableModels();
      return NextResponse.json(models);
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **HeyGen Avatar Routes**

    ```typescript
    // app/api/heygen/create-session/route.ts
    // Create a new avatar session
    export async function POST(req: Request) {
      const { avatarId, voice } = await req.json();

      const response = await fetch(
        'https://api.heygen.com/v1/streaming/new',
        {
          method: 'POST',
          headers: {
            'X-Api-Key': process.env.HEYGEN_API_KEY,
          },
          body: JSON.stringify({
            avatar_id: avatarId,
            voice,
            quality: 'high'
          })
        }
      );

      return NextResponse.json(await response.json());
    }
    ```

    ```typescript
    // app/api/heygen/list-avatars/route.ts
    // Get available avatars
    export async function GET() {
      const avatars = await fetchHeyGenAvatars();
      return NextResponse.json(avatars);
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Voice & Audio Routes**

    ```typescript
    // app/api/realtime-session/route.ts
    // Create GPT-4o Realtime session
    export async function POST() {
      const response = await fetch(
        'https://api.openai.com/v1/realtime/sessions',
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'gpt-4o-realtime-preview',
            voice: 'alloy'
          })
        }
      );

      return NextResponse.json(await response.json());
    }
    ```

    ```typescript
    // app/api/tts/route.ts
    // Text-to-Speech generation
    export async function POST(req: Request) {
      const { text, voice = 'alloy' } = await req.json();

      const response = await openai.audio.speech.create({
        model: 'tts-1',
        voice,
        input: text,
      });

      const buffer = Buffer.from(await response.arrayBuffer());
      return new Response(buffer, {
        headers: { 'Content-Type': 'audio/mpeg' }
      });
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **File Storage Routes**

    ```typescript
    // Using Supabase Storage directly in components
    import { createClient } from '@/lib/supabase/client';

    // Upload file
    const uploadFile = async (file: File) => {
      const supabase = createClient();

      const { data, error } = await supabase.storage
        .from('chat-files')
        .upload(`${Date.now()}-${file.name}`, file);

      if (error) throw error;

      // Get public URL
      const { data: { publicUrl } } = supabase.storage
        .from('chat-files')
        .getPublicUrl(data.path);

      return publicUrl;
    };

    // Delete file
    const deleteFile = async (path: string) => {
      const supabase = createClient();

      await supabase.storage
        .from('chat-files')
        .remove([path]);
    };
    ```
  </Tabs.Tab>
</Tabs>

## Testing Your Setup

Verify everything is working:

```bash
# From monorepo root (recommended)
pnpm turbo build --filter=console
pnpm turbo typecheck --filter=console
pnpm turbo lint --filter=console

# Or from console directory
cd console
pnpm build
pnpm type-check
pnpm lint
pnpm start
```

## What's Next?

Now that your console is running:

1. **Learn AI Integration**: Deep dive into [Vercel AI SDK v5](/docs/ai-integration)
2. **Set Up Avatars**: Configure [Interactive Avatars](/docs/interactive-avatars)
3. **Enable Voice**: Implement [Voice Conversations](/docs/voice-audio)
4. **Secure Your App**: Configure [Supabase RLS](/docs/supabase)
5. **Deploy**: Follow the [Production Guide](/docs/deployment)

<Callout type="success">
**You're Ready!** Your REFLEKT Console is running with GPT-4o as the primary model, plus multi-model support, interactive avatars, and voice capabilities!
</Callout>

## Troubleshooting

Common issues and solutions:

- **Supabase Connection Error**: Check your URL and anon key are correct
- **AI Model Not Available**: Ensure you've added the API key for that provider
- **Avatar Not Loading**: Verify HeyGen API key and check browser WebRTC support
- **Voice Mode Silent**: OpenAI API key required, check microphone permissions
- **File Upload Fails**: Ensure Supabase storage bucket is created with proper policies

For more help:
- Check the [GitHub Issues](https://github.com/identity-wael/reflekt-ai/issues)
- Join our Discord community
- Review the [API Documentation](/docs/api)
