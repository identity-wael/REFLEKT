---
title: AI Integration
description: Complete guide to Vercel AI SDK v5 and multi-model support
---

import { Tabs, Callout, Table } from 'nextra/components'

# Multi-Model AI Support with Vercel AI SDK v5

REFLEKT Console leverages **Vercel AI SDK v5** - a powerful TypeScript toolkit that revolutionizes AI application development. With GPT-4o as the primary model and support for 8+ AI providers, v5 brings significant improvements in streaming UI, structured data generation, and developer experience.

## Why AI SDK v5?

<Callout type="info">
**AI SDK v5 represents a major leap forward** in building AI-powered applications with enhanced type safety, streaming capabilities, and framework flexibility.
</Callout>

### Key Advantages of v5

- **Unified API**: Single consistent interface across 20+ AI providers
- **Streaming UI Components**: Real-time UI updates with built-in React hooks
- **Structured Outputs**: Type-safe object generation with Zod schemas
- **Enhanced Tool Calling**: Multi-step tool execution with automatic retry
- **Framework Agnostic**: Works with React, Next.js, Vue, Svelte, and Node.js
- **Improved DX**: Better TypeScript support and error handling
- **Telemetry & Observability**: Built-in monitoring and debugging

## Core v5 Features

The console implements a sophisticated multi-model architecture that leverages v5's capabilities:

- **Text Generation**: `generateText` and `streamText` for flexible content creation
- **Object Generation**: `generateObject` and `streamObject` for structured data
- **Tool Calling**: Advanced function calling with automatic execution
- **Streaming UI**: Real-time updates with `useChat`, `useCompletion`, and `useObject`
- **Middleware System**: Request/response interceptors for custom logic
- **Provider Abstraction**: Seamless switching between AI models

## Supported Providers

REFLEKT Console integrates with **22+ AI providers** through AI SDK v5, each offering unique capabilities:

### Provider Capabilities Quick Reference

| Provider Type | Examples | Key Features |
|---------------|----------|--------------|
| **Full-Featured** | OpenAI, Anthropic, xAI, Azure | All features: Vision, Image Gen, Tools, Streaming |
| **High-Performance** | Groq, Together AI, Fireworks | Ultra-fast inference, cost-effective |
| **Image Specialists** | Fal AI, Replicate, Stability AI | Advanced image generation models |
| **Enterprise** | Azure, Amazon Bedrock, Vertex AI | Security, compliance, private deployments |
| **Search-Enhanced** | Perplexity, Tavily | Built-in web search and real-time data |
| **Local/Self-Hosted** | Ollama, LMStudio, Baseten | Run models locally or custom deployments |

<Callout type="info">
**Complete Provider Guide**: See our comprehensive [AI SDK Provider Ecosystem](/docs/ai-sdk-providers) guide for detailed capabilities, pricing, and implementation examples for all 22+ providers.
</Callout>

### Popular Provider Examples

```typescript
// Full-featured providers
import { openai } from '@ai-sdk/openai';     // GPT-4o, DALL-E, Vision
import { anthropic } from '@ai-sdk/anthropic'; // Claude 3, 200K context
import { xai } from '@ai-sdk/xai';           // Grok 3, latest models

// High-performance providers
import { groq } from '@ai-sdk/groq';         // 800+ tokens/sec
import { fireworks } from '@ai-sdk/fireworks'; // Fast inference + image gen

// Specialized providers
import { google } from '@ai-sdk/google';     // Gemini, 1M+ context
import { mistral } from '@ai-sdk/mistral';   // European AI, multilingual
import { perplexity } from '@ai-sdk/perplexity'; // Search-enhanced responses
```



## Installation

```bash
# Core Vercel AI SDK
pnpm add ai

# Primary providers (recommended)
pnpm add @ai-sdk/openai        # GPT-4o, DALL-E, Whisper
pnpm add @ai-sdk/anthropic     # Claude 3, 200K context
pnpm add @ai-sdk/google        # Gemini Pro, 1M+ context
pnpm add @ai-sdk/xai           # Grok 3, latest models

# High-performance providers
pnpm add @ai-sdk/groq          # 800+ tokens/sec
pnpm add @ai-sdk/fireworks     # Fast inference + image gen
pnpm add @ai-sdk/togetherai    # Cost-effective, fast

# Enterprise providers
pnpm add @ai-sdk/azure         # Enterprise OpenAI
pnpm add @ai-sdk/amazon-bedrock # AWS managed models
pnpm add @ai-sdk/google-vertex # Google Cloud AI

# Specialized providers
pnpm add @ai-sdk/mistral       # European AI, multilingual
pnpm add @ai-sdk/cohere        # Enterprise NLP
pnpm add @ai-sdk/perplexity    # Search-enhanced
pnpm add @ai-sdk/fal           # Image generation
pnpm add @ai-sdk/replicate     # Custom models

# Local/Self-hosted
pnpm add @ai-sdk/ollama        # Run models locally
pnpm add @ai-sdk/lmstudio      # Local LLM studio

# Aggregators (access to 100+ models)
pnpm add @openrouter/ai-sdk-provider
```

## Basic Configuration

<Tabs items={['Provider Setup', 'Model Registry', 'Environment Variables']}>
  <Tabs.Tab>
    **Provider Setup**

    ```typescript
    // lib/models/index.ts
    import { openai } from '@ai-sdk/openai';
    import { anthropic } from '@ai-sdk/anthropic';
    import { google } from '@ai-sdk/google';
    import { mistral } from '@ai-sdk/mistral';
    import { xai } from '@ai-sdk/xai';
    import { perplexity } from '@ai-sdk/perplexity';
    import { createOpenRouter } from '@openrouter/ai-sdk-provider';

    // Initialize providers
    export const providers = {
      openai: openai,
      anthropic: anthropic,
      google: google,
      mistral: mistral,
      xai: xai,
      perplexity: perplexity,
      openrouter: createOpenRouter({
        apiKey: process.env.OPENROUTER_API_KEY
      })
    };

    // Get provider for a model
    export function getProvider(modelId: string) {
      const [provider] = modelId.split(':');
      return providers[provider];
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Model Registry**

    ```typescript
    // lib/models/data/index.ts
    export const MODEL_REGISTRY = {
      // OpenAI Models (Primary)
      'gpt-4o': {
        id: 'gpt-4o',
        name: 'GPT-4o (Primary)',
        provider: 'openai',
        contextLength: 128000,
        vision: true,
        tools: true,
        description: 'Primary model - Most capable'
      },
      'gpt-4o-mini': {
        id: 'gpt-4o-mini',
        name: 'GPT-4o Mini',
        provider: 'openai',
        contextLength: 128000,
        vision: true,
        tools: true,
        description: 'Fast and cost-effective'
      },

      // Anthropic Models (Alternative)
      'claude-3-opus-20240229': {
        id: 'claude-3-opus-20240229',
        name: 'Claude 3 Opus',
        provider: 'anthropic',
        contextLength: 200000,
        vision: true,
        tools: true,
        description: 'Alternative - Complex reasoning'
      },
      'claude-3-5-sonnet-latest': {
        id: 'claude-3-5-sonnet-latest',
        name: 'Claude 3.5 Sonnet',
        provider: 'anthropic',
        contextLength: 200000,
        vision: true,
        tools: true,
        description: 'Alternative - Fast and capable'
      },

      // Google Models (Alternative)
      'gemini-1.5-pro': {
        id: 'gemini-1.5-pro',
        name: 'Gemini 1.5 Pro',
        provider: 'google',
        contextLength: 1000000,
        vision: true,
        tools: true,
        description: 'Alternative - Large context window'
      },

      // Add more models...
    };

    // Get available models based on API keys
    export async function getAvailableModels() {
      const models = [];

      if (process.env.OPENAI_API_KEY) {
        models.push(...Object.values(MODEL_REGISTRY)
          .filter(m => m.provider === 'openai'));
      }

      if (process.env.ANTHROPIC_API_KEY) {
        models.push(...Object.values(MODEL_REGISTRY)
          .filter(m => m.provider === 'anthropic'));
      }

      // Check other providers...

      return models;
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Environment Variables**

    ```env
    # Primary Provider (Required)
    OPENAI_API_KEY=sk-...  # GPT-4o primary model

    # Alternative Providers (Optional)
    ANTHROPIC_API_KEY=sk-ant-...  # Claude 3 Opus
    GOOGLE_AI_API_KEY=AIza...  # Gemini Pro
    MISTRAL_API_KEY=...
    XAI_API_KEY=xai-...
    PERPLEXITY_API_KEY=pplx-...
    DEEPSEEK_API_KEY=...
    OPENROUTER_API_KEY=sk-or-...

    # Optional for local models
    OLLAMA_BASE_URL=http://localhost:11434
    ```
  </Tabs.Tab>
</Tabs>

## Streaming Responses

The console uses Vercel AI SDK's streaming capabilities for real-time responses:

```typescript
// app/api/chat/route.ts
import { streamText } from 'ai';
import { getProvider } from '@/lib/models';

export async function POST(req: Request) {
  const { messages, model: modelId } = await req.json();

  // Get the appropriate provider
  const provider = getProvider(modelId);
  const model = provider(modelId);

  // Stream the response
  const result = await streamText({
    model,
    messages,
    temperature: 0.7,
    maxTokens: 4096,
    onFinish: async ({ text, usage }) => {
      // Save to database
      await saveMessage({
        content: text,
        model: modelId,
        tokens: usage.totalTokens
      });
    }
  });

  // Return streaming response
  return result.toDataStreamResponse();
}
```

## New in v5: Enhanced Features

### Structured Data Generation

AI SDK v5 introduces powerful structured output capabilities with full TypeScript support:

```typescript
// app/api/extract/route.ts
import { generateObject } from 'ai';
import { z } from 'zod';

// Define your schema with Zod
const RecipeSchema = z.object({
  name: z.string(),
  ingredients: z.array(z.object({
    name: z.string(),
    amount: z.string()
  })),
  steps: z.array(z.string()),
  cookTime: z.number()
});

export async function POST(req: Request) {
  const { prompt } = await req.json();

  // Generate structured data with type safety
  const { object } = await generateObject({
    model: openai('gpt-4o'),
    schema: RecipeSchema,
    prompt: `Extract recipe information from: ${prompt}`
  });

  // object is fully typed!
  return Response.json(object);
}
```

### Streaming Structured Objects

Stream complex objects with real-time updates:

```typescript
// Stream structured data for progressive rendering
import { streamObject } from 'ai';

const { partialObjectStream } = await streamObject({
  model: openai('gpt-4o'),
  schema: z.object({
    analysis: z.string(),
    suggestions: z.array(z.string()),
    confidence: z.number()
  }),
  prompt: 'Analyze this business data...'
});

// Consume the stream with partial updates
for await (const partialObject of partialObjectStream) {
  // Update UI progressively as data arrives
  console.log(partialObject);
}
```

### Advanced Tool Calling

V5 significantly improves tool calling with automatic execution and multi-step workflows:

```typescript
// Define tools with Zod schemas
import { tool } from 'ai';

const weatherTool = tool({
  description: 'Get weather information',
  parameters: z.object({
    location: z.string(),
    unit: z.enum(['celsius', 'fahrenheit'])
  }),
  execute: async ({ location, unit }) => {
    const weather = await fetchWeather(location, unit);
    return weather;
  }
});

const calculatorTool = tool({
  description: 'Perform calculations',
  parameters: z.object({
    expression: z.string()
  }),
  execute: async ({ expression }) => {
    return eval(expression); // Simplified example
  }
});

// Use tools in conversation
const result = await generateText({
  model: openai('gpt-4o'),
  messages,
  tools: {
    weather: weatherTool,
    calculator: calculatorTool
  },
  toolChoice: 'auto', // Let the model decide
  maxToolRoundtrips: 5 // Allow multiple tool calls
});
```

### Streaming UI Components

V5 provides powerful hooks for building responsive AI interfaces:

```typescript
// useObject hook for streaming structured data
import { useObject } from 'ai/react';

function DataExtractor() {
  const { object, submit, isLoading, error } = useObject({
    api: '/api/extract',
    schema: z.object({
      summary: z.string(),
      keyPoints: z.array(z.string()),
      sentiment: z.enum(['positive', 'neutral', 'negative'])
    })
  });

  return (
    <div>
      {/* Real-time updates as object streams */}
      {object?.summary && <p>{object.summary}</p>}
      {object?.keyPoints?.map((point, i) => (
        <li key={i}>{point}</li>
      ))}
    </div>
  );
}
```

### Middleware System

Add custom logic to all AI requests:

```typescript
// lib/ai/middleware.ts
import { experimental_wrapLanguageModel } from 'ai';

const modelWithMiddleware = experimental_wrapLanguageModel({
  model: openai('gpt-4o'),
  middleware: {
    // Pre-process requests
    transformParams: async (params) => {
      return {
        ...params,
        messages: addSystemPrompt(params.messages)
      };
    },
    // Post-process responses
    wrapGenerate: async (generateFn) => {
      const result = await generateFn();
      await logUsage(result);
      return result;
    }
  }
});
```

## Client-Side Integration

<Tabs items={['useChat Hook', 'Custom Implementation', 'Multi-Model Chat']}>
  <Tabs.Tab>
    **Using useChat Hook**

    ```typescript
    // components/chat/chat.tsx
    import { useChat } from 'ai/react';

    export function Chat() {
      const {
        messages,
        input,
        handleInputChange,
        handleSubmit,
        isLoading,
        error
      } = useChat({
        api: '/api/chat',
        body: {
          model: selectedModel
        },
        onError: (error) => {
          console.error('Chat error:', error);
        }
      });

      return (
        <div>
          {messages.map((message) => (
            <Message key={message.id} message={message} />
          ))}

          <form onSubmit={handleSubmit}>
            <input
              value={input}
              onChange={handleInputChange}
              placeholder="Type a message..."
              disabled={isLoading}
            />
          </form>
        </div>
      );
    }
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Custom Implementation**

    ```typescript
    // lib/chat-store/session/provider.tsx
    import { create } from 'zustand';

    interface ChatState {
      messages: Message[];
      isStreaming: boolean;
      currentModel: string;
      sendMessage: (content: string) => Promise<void>;
    }

    export const useChatStore = create<ChatState>((set, get) => ({
      messages: [],
      isStreaming: false,
      currentModel: 'gpt-4o',  // Default to primary model

      sendMessage: async (content: string) => {
        set({ isStreaming: true });

        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            messages: [...get().messages, { role: 'user', content }],
            model: get().currentModel
          })
        });

        if (!response.ok) throw new Error('Failed to send message');

        // Handle streaming response
        const reader = response.body?.getReader();
        const decoder = new TextDecoder();
        let assistantMessage = '';

        while (reader) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value);
          assistantMessage += chunk;

          // Update UI with streaming text
          set(state => ({
            messages: [
              ...state.messages.slice(0, -1),
              { role: 'assistant', content: assistantMessage }
            ]
          }));
        }

        set({ isStreaming: false });
      }
    }));
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Multi-Model Chat**

    ```typescript
    // components/multi-chat/use-multi-chat.ts
    export function useMultiChat() {
      const [chats, setChats] = useState<MultiChatSession[]>([]);

      const sendToAllModels = async (message: string) => {
        const models = ['gpt-4o', 'claude-3-opus-20240229', 'gemini-1.5-pro'];  // Primary + alternatives

        // Send to all models in parallel
        const promises = models.map(async (model) => {
          const response = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              messages: [{ role: 'user', content: message }],
              model
            })
          });

          return {
            model,
            response: await response.text()
          };
        });

        const results = await Promise.all(promises);
        setChats(results);
      };

      return { chats, sendToAllModels };
    }
    ```
  </Tabs.Tab>
</Tabs>

## Advanced Features

### Tool Calling

```typescript
// lib/tools/ai-tools.ts
import { tool } from 'ai';
import { z } from 'zod';

export const aiTools = {
  searchWeb: tool({
    description: 'Search the web for information',
    parameters: z.object({
      query: z.string(),
      limit: z.number().optional()
    }),
    execute: async ({ query, limit = 5 }) => {
      // Implement web search logic
      return {
        results: [],
        source: 'web'
      };
    }
  }),

  analyzeData: tool({
    description: 'Analyze data and provide insights',
    parameters: z.object({
      data: z.array(z.any()),
      analysisType: z.enum(['summary', 'trend', 'comparison'])
    }),
    execute: async ({ data, analysisType }) => {
      // Implement data analysis logic
      return { analysis: 'Data analysis result' };
    }
  })
};

// Use in chat with GPT-4o (primary model)
const result = await streamText({
  model: openai('gpt-4o'),
  messages,
  tools: aiTools,
  toolChoice: 'auto'
});
```

### Vision Capabilities

```typescript
// Handle image uploads
export async function analyzeImage(imageUrl: string, prompt: string) {
  const result = await streamText({
    model: openai('gpt-4o'),
    messages: [
      {
        role: 'user',
        content: [
          { type: 'text', text: prompt },
          { type: 'image', image: imageUrl }
        ]
      }
    ]
  });

  return result;
}
```

### Error Handling

```typescript
// lib/ai/error-handler.ts
export async function withRetry<T>(
  fn: () => Promise<T>,
  retries = 3,
  delay = 1000
): Promise<T> {
  try {
    return await fn();
  } catch (error) {
    if (retries === 0) throw error;

    // Handle rate limits
    if (error.status === 429) {
      const retryAfter = error.headers?.['retry-after'] || delay;
      await new Promise(resolve => setTimeout(resolve, retryAfter));
      return withRetry(fn, retries - 1, delay * 2);
    }

    // Handle other errors
    throw error;
  }
}

// Usage
const response = await withRetry(() =>
  streamText({
    model: openai('gpt-4o'),
    messages
  })
);
```

## Model-Specific Features

<Callout type="info">
Each provider has unique capabilities. The console automatically adjusts features based on the selected model.
</Callout>

### OpenAI o1 Models
- Reasoning tokens for complex problems
- No streaming support (full response only)
- Higher latency but better accuracy

### Anthropic Claude (Alternative)
- Claude 3 Opus: 200K context window
- Superior at following complex instructions
- Alternative to GPT-4o for creative and analytical tasks

### Google Gemini
- 1M+ context window
- Native multimodal understanding
- Excellent for document analysis

### Perplexity Sonar
- Built-in web search
- Real-time information
- Citation support

## Performance Optimization

### Caching Responses

```typescript
// lib/cache/ai-cache.ts
import { kv } from '@vercel/kv';

export async function getCachedResponse(key: string) {
  return await kv.get(key);
}

export async function setCachedResponse(
  key: string,
  response: any,
  ttl = 3600
) {
  await kv.set(key, response, { ex: ttl });
}
```

### Load Balancing

```typescript
// lib/ai/load-balancer.ts
export class ModelLoadBalancer {
  private modelPool = [
    'gpt-4o',  // Primary model
    'claude-3-opus-20240229',  // Alternative 1
    'gemini-1.5-pro'  // Alternative 2
  ];
  private currentIndex = 0;

  getNextModel(): string {
    const model = this.modelPool[this.currentIndex];
    this.currentIndex = (this.currentIndex + 1) % this.modelPool.length;
    return model;
  }
}
```

## Monitoring & Analytics

```typescript
// lib/analytics/ai-metrics.ts
export async function trackAIUsage({
  model,
  tokens,
  latency,
  success
}: AIMetrics) {
  await fetch('/api/analytics', {
    method: 'POST',
    body: JSON.stringify({
      event: 'ai_usage',
      properties: {
        model,
        tokens,
        latency,
        success,
        timestamp: new Date().toISOString()
      }
    })
  });
}
```

## V5 Migration Benefits

<Callout type="success">
**Upgrading to AI SDK v5** provides immediate benefits in performance, type safety, and developer experience.
</Callout>

### Performance Improvements
- **Faster streaming**: Optimized data transfer with partial JSON streaming
- **Reduced latency**: Better connection pooling and request batching
- **Smaller bundle size**: Tree-shakeable exports and modular architecture

### Developer Experience
- **Type Safety**: Full TypeScript support with inferred types from Zod schemas
- **Better Errors**: Detailed error messages with actionable fixes
- **Simplified API**: Consistent patterns across all functions
- **Framework Support**: First-class support for React Server Components

### New Capabilities
- **Structured Outputs**: Generate type-safe objects and arrays
- **Multi-modal Support**: Handle text, images, and files seamlessly
- **Tool Chaining**: Complex multi-step tool execution workflows
- **Observability**: Built-in telemetry and debugging tools

## Best Practices with v5

1. **Use structured outputs** for data extraction tasks
2. **Leverage streaming UI hooks** for responsive interfaces
3. **Implement middleware** for cross-cutting concerns
4. **Use `generateText` for batch operations** and `streamText` for interactive UIs
5. **Define Zod schemas** for all structured data generation
6. **Enable telemetry** in production for monitoring
7. **Use tool calling** for complex workflows
8. **Implement proper error boundaries** with v5's error types
9. **Cache with `unstable_cache`** for expensive operations
10. **Monitor usage** with built-in metrics

## Next Steps

- [AI SDK Provider Ecosystem](/docs/ai-sdk-providers) - Complete guide to all 22+ providers
- [AI SDK v5 Features](/docs/ai-sdk-v5-features) - Deep dive into v5 capabilities
- [Interactive Avatars](/docs/interactive-avatars) - Add HeyGen avatars to your chat
- [Voice Mode](/docs/voice-audio) - Enable real-time voice conversations
- [API Reference](/docs/api) - Complete API documentation
- [Security](/docs/security) - Best practices for AI security
